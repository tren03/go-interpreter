We created the token type, by defining a struct which has value, type of token, and defined all the token types possible

create a lexer, which parses the code to generate tokens, currently writing tests for the lexer step by step. Learnt about the testing library of go (should implement in on my website)
just created a basic text, with input and expected tokens.
Now moving on, if we encounter a letter, it might be a string indentifier of a keyword, so just coded the logic for that
Now lexer detects keywords too, to do this, we pass the string detected into a LookupIdent which returns type of token, be it a command or identifier
Now we added a helper func in NextToken func to skip whitespaces, by checking current char in lexer struct
Now added a helper func to detect a int, and if its a number, keep reading until not number and retrurn the string (handling int in our lang)

we will add support for ==, !, !=, -, /, *, <, > and the keywords true, false, if, else and return.
we first add 1 char tokens like !, -, /, *, <, >  (pretty easy as we can just follow what we did for above tokens)
we then add new keywords to the lexer true,false,if,else,return
to add support for ==,!= we extend the = and ! branches to look ahead and check to return proper token

We create a REPL (read,eval,print,loop) like a console for our lang, for now the repl will only convert our source code into tokens
Need to do the parsing part staring from the ast package

our parser for the Monkey programming language -> Its input
will be the tokens we defined in the previous chapter, produced by the lexer we already wrote.
We will define our own AST, suited to our needs as interpreters of the Monkey programming
language, and construct instances of this AST while recursively parsing tokens.
Parse generators -> generate parsers when fed a formal description of the language like yacc, bison or ANTLR

The parser we are going to write is a recursive descent parser. And in particular, it’s a “top
down operator precedence” parser, sometimes called “Pratt parser”, after its inventor Vaughan
Pratt.
A recursive descent
parser, which works from the top down, is often recommended for newcomers to parsing, since
it closely mirrors the way we think about ASTs and their construction.

first we parse the let statment   
// Every node in ast implements the node interface, meaning it has to provide a TokenLiteral() method, -> just to debug. Some of the nodes implement statement interface and some expression interface.
a let can have a literal or expression on the right side, so we neeed to define how it will look in ast

we parse the return and let statement, by forming a ast based on the tokens we recieve. let and return are the only statements, rest all are expressions
now we go on to parse expressions.

A Pratt parser’s main idea is the association of parsing functions (which Pratt calls “semantic
code”) with token types. Whenever this token type is encountered, the parsing functions are
called to parse the appropriate expression and return an AST node that represents it. Each
token type can have up to two parsing functions associated with it, depending on whether the
token is found in a prefix or an infix position.

parsing expression is more complex and interesting as we need to take care of operator precedence and brackets


Monkey has expressions involving prefix operators:
-5
!true
!false

And of course it has infix operators (or “binary operators”):
5 + 5
5 - 5
5 / 5
5 * 5

Besides these basic arithmetic operators, there are also the following comparison operators:
foo == bar
foo != bar
foo < bar
foo > bar

And of course, as we previously saw, we can use parentheses to group expressions and influence
the order of evaluation:
5 * (5 + 5)
((5 + 5) * 5) * 5

Then there are call expressions:
add(2, 3)
add(add(2, 3), add(5, 10))
max(5, add(5, (5 * 5)))

Identifiers are expressions too:
foo * bar / foobar
add(foo, bar)

let add = fn(x, y) { return x + y };
And here we use a function literal in place of an identifier:
fn(x, y) { return x + y }(5, 5)
(fn(x) { return x }(5) + 10 ) * 10
In contrast to a lot of widely used programming languages we also have “if expressions” in
Monkey:
let result = if (10 > 5) { true } else { false };
result // => true


A Pratt parser’s main idea is the association of parsing functions (which Pratt calls “semantic
code”) with token types. Whenever this token type is encountered, the parsing functions are
called to parse the appropriate expression and return an AST node that represents it. Each
token type can have up to two parsing functions associated with it, depending on whether the
token is found in a prefix or an infix position.

we added a map for infix and postfix func where the key is the token
we start with identifiers

add(foobar, barfoo);
foobar + barfoo;
if (foobar) {
// [...]
}
Here we have identifiers as arguments in a function call, as operands in an infix expression and
as a standalone expression as part of a conditional. They can be used in all of these contexts,
because identifiers are expressions just like 1 + 2. And just like any other expression identifiers
produce a value: they evaluate to the value they are bound to.

we build a identifier test in parser

l: we build our AST node and then try to fill its field by calling other
parsing functions. 
